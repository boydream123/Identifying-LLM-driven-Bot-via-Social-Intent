# --- Core Deep Learning Framework ---
# PyTorch 2.x is recommended for better support of VLM backbones (e.g., Qwen2-VL)
torch>=2.1.0
torchvision>=0.16.0

# --- Transformers & VLM Backbones ---
# Required for loading Qwen2-VL, LLaVA, and handling Tokenization
transformers>=4.37.0
tokenizers>=0.15.0
accelerate>=0.26.0  # For efficient model loading and multi-GPU support

# --- Parameter-Efficient Fine-Tuning (LoRA) ---
# Essential for implementing SIFT's Eq. 4 (Low-Rank Adaptation)
peft>=0.7.0

# --- Data Processing & Image Handling ---
numpy>=1.24.0
pandas>=2.0.0       # For handling TwiBot-22/Weibo CSV/JSON datasets
Pillow>=10.0.0      # For image loading and patching

# --- Optimization & Quantization (Optional but Recommended) ---
# Useful if running large VLMs on consumer GPUs
bitsandbytes>=0.41.0
einops>=0.7.0       # Often required by specific VLM architectures

# --- Metrics & Evaluation ---
# Required for calculating Accuracy, F1-Score, and AUROC (Table 2)
scikit-learn>=1.3.0

# --- Utilities ---
tqdm>=4.66.0        # For training progress bars
matplotlib>=3.8.0   # For visualizing the Intent Manifold (Figure 1 & 3)
